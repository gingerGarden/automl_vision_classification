{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from scripts.default_setting import *\n",
    "\n",
    "from Garden.utils.path import do_or_load, GetAbsolutePath\n",
    "from Garden.utils.process.process import get_verbose, get_process_id\n",
    "from Garden.utils.log.dl import Log\n",
    "from Garden.utils.process.dl import code_test, set_seed_everything, make_basic_directory, GetDevice, Option\n",
    "from Garden.dl.idx_dict.keys import make_basic_key_df, binary_label_convertor\n",
    "from Garden.dl.idx_dict.make_dict import StratifiedIndexdict\n",
    "from Garden.dl.loader.classification import BasicDataset\n",
    "from Garden.dl.loader.helper import LabelDtype\n",
    "from Garden.dl.model.vision import TimmHelper\n",
    "from Garden.dl.model.optimizer import OptimHelper, SchedulerHelper\n",
    "from Garden.dl.metrics.classification import MetricsClassification as Metrics\n",
    "from Garden.augment.img.scenario import sample_scenario\n",
    "from Garden.statics.descript import frequency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option\n",
    "#### Option 1. basic option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      "GPU size: 2\n",
      "------------------------------------------------------------\n",
      "GPU number: 0\n",
      "Name: NVIDIA GeForce RTX 3080 Ti\n",
      "Computer capability: 8.6\n",
      "VRAM: 12GB\n",
      "------------------------------------------------------------\n",
      "GPU number: 1\n",
      "Name: NVIDIA GeForce GTX 750\n",
      "Computer capability: 5.0\n",
      "VRAM: 1GB\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# gpu 상태 확인\n",
    "GET_DEVICE = GetDevice()\n",
    "GET_DEVICE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 process의 id:  942773\n",
      "[Code Test]: Code test를 하지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "# Process 기본 설정\n",
    "#######################################\n",
    "# Process 상태 출력\n",
    "VERBOSE = True\n",
    "# code test 여부\n",
    "CODE_TEST = False\n",
    "# log save 여부\n",
    "SAVE_LOG = True\n",
    "# GPU 번호\n",
    "GPU = 0\n",
    "# process 진행 중 생성되는 파일들이 저장되는 초기 디렉터리 초기화 여부\n",
    "MAKE_NEW_DEFAULT_DIR = True\n",
    "# idx_dict을 새로 생성할지 여부\n",
    "MAKE_NEW_IDX_DICT = True\n",
    "# 모델의 종류\n",
    "MODEL_TYPE = \"classification\"\n",
    "# 이진 분류 여부\n",
    "IS_BINARY = True\n",
    "\n",
    "\n",
    "# Data 설정\n",
    "#######################################\n",
    "# image의 크기\n",
    "IMG_SIZE = 224\n",
    "# index dictionary 생성 방식\n",
    "K_FOLD = 5                  # k-fold의 크기 (Stratified sampling)\n",
    "TEST_RATIO = 0.2            # test dataset ratio\n",
    "VALID_RATIO = 0.1           # validation dataset ratio, None인 경우 생성하지 않음\n",
    "\n",
    "\n",
    "# 자동 설정\n",
    "#######################################\n",
    "_VERBOSE = get_verbose(verbose=VERBOSE)\n",
    "_PROCESS_ID = get_process_id(verbose=_VERBOSE)\n",
    "_CODE_TEST = code_test(do=CODE_TEST, test_ratio=0.1, verbose=_VERBOSE)\n",
    "\n",
    "# device 설정\n",
    "_DEVICE = GET_DEVICE(GPU)\n",
    "torch.cuda.set_device(_DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnet_b3.ra2_in1k',\n",
       " 'efficientnet_b3_pruned.in1k',\n",
       " 'efficientvit_b3.r224_in1k',\n",
       " 'efficientvit_b3.r256_in1k',\n",
       " 'efficientvit_b3.r288_in1k',\n",
       " 'tf_efficientnet_b3.aa_in1k',\n",
       " 'tf_efficientnet_b3.ap_in1k',\n",
       " 'tf_efficientnet_b3.in1k',\n",
       " 'tf_efficientnet_b3.ns_jft_in1k',\n",
       " 'tf_efficientnetv2_b3.in1k',\n",
       " 'tf_efficientnetv2_b3.in21k',\n",
       " 'tf_efficientnetv2_b3.in21k_ft_in1k']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timm에서 사용하고자 하는 모델의 이름을 찾는다.\n",
    "model_name_ptn = r\"efficient.+_b3\"\n",
    "TimmHelper.search(model_name_ptn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 관련 설정\n",
    "#######################################\n",
    "# model 이름\n",
    "MODEL_NAME = 'efficientnet_b3.ra2_in1k'\n",
    "# pre-training 여부\n",
    "PRETRAINED = True\n",
    "# Fine tuning 방식\n",
    "    # 0:FullFineTuning\n",
    "    # 1:FixedFeatureExtractor\n",
    "    # 2:PartialLayerFreezing\n",
    "    # 3:FreezeNUnfreeze\n",
    "TUNER_DICT = {\n",
    "    'how':2,\n",
    "    'freezing_ratio':0.9\n",
    "}\n",
    "# image의 channel 크기\n",
    "IMG_CHANNEL = 3\n",
    "# model이 추론할 class의 크기\n",
    "CLASS_SIZE = 0\n",
    "# 모델 추론을 위한 metrics\n",
    "METRICS = Metrics(is_binary=True, threshold=0.5)\n",
    "\n",
    "# header 관련 설정\n",
    "#######################################\n",
    "from scripts.header import custom_binary_header, EXTRA_ACTIVATION_FN\n",
    "\n",
    "# backbone 모델의 새로운 header\n",
    "CUSTOM_HEAD_FN = custom_binary_header\n",
    "# 손실 함수\n",
    "LOSS_FN = nn.BCEWithLogitsLoss()\n",
    "# label의 dtype을 loss function에 맞게 설정\n",
    "LABEL_DTYPE_INS = LabelDtype(loss_fn=LOSS_FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 3. pipe line setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe line 내 각종 설정\n",
    "#######################################\n",
    "# AMP 사용 여부\n",
    "USE_AMP = True\n",
    "# Grad clipping 사용 여부\n",
    "USE_CLIPPING = True\n",
    "# Early Stopping 관련 설정\n",
    "EARLY_STOPPING = {\n",
    "    \"patience\":10,\n",
    "    \"delta\":0.0,\n",
    "    \"target\":\"loss\",\n",
    "    \"auto_remove\":True,\n",
    "    \"best_model_dir\":f\"{RESULT}/{_PROCESS_ID}\"\n",
    "}\n",
    "\n",
    "# data loader 관련 설정\n",
    "#######################################\n",
    "DATASET_CLASS = BasicDataset           # dataset의 class\n",
    "TRAINSET_KWARGS = {\n",
    "    \"augments\":sample_scenario, \n",
    "    \"resize\":IMG_SIZE,\n",
    "    \"resize_how\":0,                  # resize 방법\n",
    "    \"resize_how_list\":[2, 3, 4],     # 무작위 resize 시, 방법의 list\n",
    "    \"resize_padding_color\":\"random\"  # # resize padding 시, pixel의 색\n",
    "}\n",
    "VALIDSET_KWARGS = {\n",
    "    \"resize\":IMG_SIZE,\n",
    "    \"resize_how\":2,                  # resize 방법\n",
    "    \"resize_padding_color\":\"black\"  # # resize padding 시, pixel의 색\n",
    "}\n",
    "WORKER = 4                          # DataLoader의 num_worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 4. hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter 관련 설정\n",
    "#######################################\n",
    "HP_DICT = {\n",
    "    'epochs':1000,\n",
    "    'batch_size':64,\n",
    "    \n",
    "    # Optimizer\n",
    "    'lr':0.00001,\n",
    "    'betas':(0.9, 0.999),\n",
    "    'eps':1e-08,\n",
    "    \n",
    "    # Scheduler\n",
    "    'T_0':20,\n",
    "    'T_mult':1,\n",
    "    'eta_min':0.000001,\n",
    "    \n",
    "    # clipping\n",
    "    'clipping_max_norm':5\n",
    "}\n",
    "\n",
    "# Optimizer 정의\n",
    "OPTIM_HELPER = OptimHelper(name='Adam', hp_dict=HP_DICT)\n",
    "# Scheduler 정의\n",
    "SCHEDULE_HELPER = SchedulerHelper(name='CosineAnnealingWarmRestarts', hp_dict=HP_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "#### Process 1. make key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/cat.0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/cat.1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/cat.10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/cat.100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/cat.1000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/dog.9995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/dog.9996.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/dog.9997.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/dog.9998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/dog.9999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path  label\n",
       "0         /mnt/d/rawdata/dogs-vs-cats/train/cat.0.jpg      0\n",
       "1         /mnt/d/rawdata/dogs-vs-cats/train/cat.1.jpg      0\n",
       "2        /mnt/d/rawdata/dogs-vs-cats/train/cat.10.jpg      0\n",
       "3       /mnt/d/rawdata/dogs-vs-cats/train/cat.100.jpg      0\n",
       "4      /mnt/d/rawdata/dogs-vs-cats/train/cat.1000.jpg      0\n",
       "...                                               ...    ...\n",
       "24995  /mnt/d/rawdata/dogs-vs-cats/train/dog.9995.jpg      1\n",
       "24996  /mnt/d/rawdata/dogs-vs-cats/train/dog.9996.jpg      1\n",
       "24997  /mnt/d/rawdata/dogs-vs-cats/train/dog.9997.jpg      1\n",
       "24998  /mnt/d/rawdata/dogs-vs-cats/train/dog.9998.jpg      1\n",
       "24999  /mnt/d/rawdata/dogs-vs-cats/train/dog.9999.jpg      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 경로 정보\n",
    "TRAIN_SET = \"/mnt/d/rawdata/dogs-vs-cats/train/\"        # train set의 경로\n",
    "TEST_SET = \"/mnt/d/rawdata/dogs-vs-cats/test1/\"         # test set의 경로\n",
    "\n",
    "\n",
    "# key_df 생성\n",
    "path_list = GetAbsolutePath(None).get_all_path(parents_path=TRAIN_SET)\n",
    "key_df = make_basic_key_df(\n",
    "    paths=path_list,\n",
    "    labels=[re.split(r\".+/\", i, maxsplit=1)[1].split('.')[0] for i in path_list]\n",
    ")\n",
    "# label을 이진 분류로 변환\n",
    "key_df['label'] = binary_label_convertor(array=key_df['label'], positive_class='dog')\n",
    "\n",
    "# 이해를 돕기 위한 key_df 출력\n",
    "key_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process 2. make idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_dict의 경로\n",
    "IDX_DICT_PATH = f\"{SOURCE}/idx_dict.pickle\"\n",
    "\n",
    "# 기초 디렉터리 생성\n",
    "make_basic_directory(source=SOURCE, estop_dir=ESPOINT_DIR, log=LOG, result=RESULT, make_new=MAKE_NEW_DEFAULT_DIR)\n",
    "\n",
    "# Process log 설정\n",
    "LOG_INS = Log(log_dir=LOG, process_id=_PROCESS_ID, model_type=MODEL_TYPE, save_log=SAVE_LOG)\n",
    "\n",
    "# index dictionary 생성\n",
    "make_index_dict = StratifiedIndexdict(columns=['label'], is_binary=IS_BINARY)\n",
    "IDX_DICT = do_or_load(\n",
    "    savepath=IDX_DICT_PATH, makes_new=MAKE_NEW_IDX_DICT, \n",
    "    fn=make_index_dict,\n",
    "    key_df=key_df, k_fold_size=K_FOLD, test_ratio=TEST_RATIO, valid_ratio=VALID_RATIO, code_test=_CODE_TEST\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process 3. make option instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = Option(\n",
    "    process_id=_PROCESS_ID, verbose=_VERBOSE, log_ins=LOG_INS,\n",
    "    model_name=MODEL_NAME, pretrained=PRETRAINED, device=_DEVICE, use_amp=USE_AMP, use_clipping=USE_CLIPPING,\n",
    "    img_channel=IMG_CHANNEL, class_size=CLASS_SIZE, custom_header=CUSTOM_HEAD_FN, extra_activation_fn=EXTRA_ACTIVATION_FN,\n",
    "    metrics=METRICS,\n",
    "    optim_helper=OPTIM_HELPER, scheduler_helper=SCHEDULE_HELPER, loss_fn=LOSS_FN, label_dtype_fn=LABEL_DTYPE_INS, \n",
    "    tuner_dict=TUNER_DICT, hp_dict=HP_DICT, \n",
    "    dataset_class=DATASET_CLASS, trainset_kwargs=TRAINSET_KWARGS, validset_kwargs=VALIDSET_KWARGS, worker=WORKER,\n",
    "    idx_dict=IDX_DICT, results_parents=RESULT, espoint_parents=f\"{SOURCE}/{ESPOINT_DIR}\",\n",
    "    early_stopping=EARLY_STOPPING\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process 4. model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Garden.dl.pipeline.pipeline import BackPropagation, EarlyStopping\n",
    "from Garden.dl.model.fine_tuning import Tuner\n",
    "from Garden.dl.model.vision import Classification as Model\n",
    "from Garden.dl.loader.classification import GetLoader\n",
    "from Garden.dl.pipeline.fit.classification import Classification as Fit\n",
    "from Garden.utils.path import new_dir_maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 전 모든 seed 고정\n",
    "set_seed_everything(seed=SEED)\n",
    "\n",
    "# k-fold cross validation\n",
    "for k in option.idx_dict.keys():\n",
    "    k_idx_dict = option.idx_dict[k]     # k-fold에 대한 idx_dict\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "option.log_ins.k = k        # log의 k값 설정\n",
    "\n",
    "# 결과가 저장될 디렉터리 생성\n",
    "new_dir_maker(dir_path=f\"{option.results_parents}/{option.process_id}\")\n",
    "\n",
    "# Data Loader 정의\n",
    "loader = GetLoader(\n",
    "    idx_dict=k_idx_dict, dataset_class=option.dataset_class, \n",
    "    batch_size=option.hp_dict['batch_size'], workers=option.worker\n",
    ")\n",
    "loader(key=\"train\", **option.trainset_kwargs)\n",
    "loader(key=\"test\", **option.validset_kwargs)\n",
    "if \"valid\" in k_idx_dict:\n",
    "    loader(key=\"valid\", **option.validset_kwargs)\n",
    "\n",
    "# model 정의\n",
    "model = Model(\n",
    "    model_name=option.model_name, pretrained=option.pretrained, \n",
    "    channel=option.img_channel, class_size=option.class_size,\n",
    "    custom_head_fn=option.custom_header\n",
    ").to(option.device)\n",
    "\n",
    "# Optimizer 설정\n",
    "optimizer = option.optim_helper(param=model.parameters())\n",
    "back_propagation = BackPropagation(\n",
    "    optimizer=optimizer, use_amp=option.use_amp, \n",
    "    use_clipping=option.use_clipping, \n",
    "    max_norm=option.hp_dict['clipping_max_norm'] if 'clipping_max_norm' in option.hp_dict else None,\n",
    "    device=option.device\n",
    ")\n",
    "# scheduler 설정\n",
    "option.scheduler_helper(optimizer)\n",
    "\n",
    "# Early Stopping 설정\n",
    "if option.early_stopping is not None:\n",
    "    early_stopping = EarlyStopping(\n",
    "        model=model, path=f\"{option.espoint_parents}/{option.process_id}.pt\", \n",
    "        **option.early_stopping\n",
    "    )\n",
    "    early_stopping.k = k\n",
    "else:\n",
    "    early_stopping = None\n",
    "\n",
    "# Fine tuning 방법 정의\n",
    "tuner = Tuner(model, **option.tuner_dict)\n",
    "tuner(epoch=0)      # model parameter 초기 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Garden.dl.pipeline.fit.utils import get_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INS = Fit(\n",
    "    model=model, loader=loader, optimizer=optimizer, \n",
    "    back_propagation=back_propagation, early_stopping=early_stopping, option=option\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    [#........................................](   18/ 1000)\n",
      "[learning rate]: 0.000001\n",
      "[Metrics] [Train]: acc: 0.94957, loss: 0.12286 / [valid]: acc: 0.97000, loss: 0.13427 / [Test]: acc: 0.97300, loss: 0.15648\n",
      "[time] spent: 0:17:44.04, eta: 15:17:30.44, 56.002s/it, current: 2024.12.02 16:43:36\n",
      "[memory] used:10.302 gb/62.707 gb (18.4 %), rest:51.175 gb, process:2.474 gb, cpu:2.3 %\n",
      "[Early Stopping - Load]: [epoch]: 8 / [best score]: 0.07899\n"
     ]
    }
   ],
   "source": [
    "epoch_log_txt = None\n",
    "for bar_txt, epoch in TEST_INS.pbar_ins(range(option.hp_dict['epochs'])):\n",
    "\n",
    "    # Epochs 시작 시 log txt\n",
    "    epoch_log_txt = TEST_INS.option.log_ins.epoch_log_txt(epoch_log_txt=epoch_log_txt, bar_txt=bar_txt)\n",
    "\n",
    "    # model training\n",
    "    train_loss, train_acc = TEST_INS._fit_iterator(epoch, epoch_log_txt)\n",
    "\n",
    "    # validation and early stopping\n",
    "    if TEST_INS.loader.valid is not None:\n",
    "        valid_loss, valid_acc, _ = TEST_INS.inference(loader=TEST_INS.loader.valid)\n",
    "        \n",
    "        # Early stopping\n",
    "        if TEST_INS.early_stopping_mask:\n",
    "            valid_score = TEST_INS.early_stopping.validation_score(loss=valid_loss, acc=valid_acc)\n",
    "            es_log_txt = TEST_INS.early_stopping(epoch, score=valid_score)\n",
    "    else:\n",
    "        valid_loss, valid_acc = (None, None)\n",
    "        \n",
    "    # scheduler 조정\n",
    "    scheduler_score = valid_loss if valid_loss is not None else train_loss\n",
    "    TEST_INS.option.scheduler_helper.epoch_step(score=scheduler_score)\n",
    "        \n",
    "    # epoch 내 log 출력\n",
    "    epoch_log_txt = TEST_INS._epoch_log(\n",
    "        bar_txt, es_log_txt, epoch, \n",
    "        train_acc, train_loss, valid_acc, valid_loss\n",
    "    )\n",
    "    # Early stopping stop\n",
    "    if TEST_INS.early_stopping.stop:\n",
    "        break\n",
    "\n",
    "# 학습 종료 후, test set에 대한 지표 생성 및 log 출력\n",
    "test_predict_dict = TEST_INS.end_of_fit(epoch, bar_txt, train_acc, train_loss, valid_acc, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_e4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
