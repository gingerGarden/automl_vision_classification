{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Tuple, Callable, Union, Optional\n",
    "\n",
    "import sys, os, cv2, re\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.default_setting import *\n",
    "\n",
    "from GGUtils.utils.path import do_or_load, GetAbsolutePath\n",
    "from GGUtils.img.viewer import show_img, show_imgs\n",
    "from GGUtils.utils.utils import time_checker\n",
    "from GGDL.utils import set_seed_everything, make_basic_directory, tensor_to_img, GetDevice, Option\n",
    "from GGDL.idx_dict.key_df import make_basic_key_df, binary_label_convertor\n",
    "from GGDL.idx_dict.make_dict import make_stratified_idx_dict\n",
    "from GGDL.data_loader.dataset import ImgDataset, GetLoader, show_dataset_img\n",
    "from GGDL.model.vision import Classification, TimmHelper\n",
    "from GGDL.model.fine_tuning import Tuner\n",
    "from GGDL.model.optimzer import Optim, LabelDtype\n",
    "from GGDL.pipeline.pipeline import BackPropagation\n",
    "\n",
    "from GGImgMorph.scenario import sample_augment      # 증강 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 process의 id:  3813287\n"
     ]
    }
   ],
   "source": [
    "# process id\n",
    "PROCESS_ID = os.getpid()\n",
    "print(\"해당 process의 id: \", PROCESS_ID)\n",
    "\n",
    "# 학습 상태 출력\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mobilenetv1_100.ra4_e3600_r224_in1k',\n",
       " 'mobilenetv1_100h.ra4_e3600_r224_in1k',\n",
       " 'mobilenetv1_125.ra4_e3600_r224_in1k']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timm에서 사용하고자 하는 모델의 이름을 찾는다.\n",
    "_model_name_ptn = \"mobilenetv1_.+_r224\"\n",
    "TimmHelper.search(_model_name_ptn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 관련 설정\n",
    "MODEL_NAME = 'mobilenetv1_100.ra4_e3600_r224_in1k'      # baseline model\n",
    "IMG_CHANNEL = 3              # image의 channel 크기\n",
    "CLASS_SIZE = 0               # model이 추론할 class의 크기\n",
    "PRETRAINED = True\n",
    "USE_AMP = True               # AMP 사용 여부\n",
    "USE_CLIPPING = True          # Grad clipping 사용 여부\n",
    "\n",
    "\n",
    "# Custom header\n",
    "class HeaderBlock(nn.Module):\n",
    "    def __init__(self, input_dim:int, output_dim:int, dropout_prob:float):\n",
    "        super(HeaderBlock, self).__init__()\n",
    "        self.batch_norm = nn.BatchNorm1d(input_dim)\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.gelu(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "def custom_header(x:int)->nn.Module:\n",
    "    \"\"\"\n",
    "    Pre-Activation Batch Normalization\n",
    "    - 깊은 Backbone 모델의 header이므로, Internal Covariate Shift 문제 해결을 위해 사용\n",
    "\n",
    "    BottleNeck\n",
    "    - 정보를 확장하여 중요한 정보만 남겨, 계산 효율성을 유지하면서 높은 표현력 제공\n",
    "    \"\"\"\n",
    "    header = nn.Sequential(\n",
    "        HeaderBlock(input_dim=x, output_dim=1024, dropout_prob=0.1),\n",
    "        HeaderBlock(input_dim=1024, output_dim=512, dropout_prob=0.3),\n",
    "        HeaderBlock(input_dim=512, output_dim=128, dropout_prob=0.5),\n",
    "        nn.Linear(128, 1)\n",
    "    )\n",
    "    return header\n",
    "\n",
    "CUSTOM_HEAD_FN = custom_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2. pipe line setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      "GPU size: 2\n",
      "------------------------------------------------------------\n",
      "GPU number: 0\n",
      "Name: NVIDIA GeForce RTX 3080 Ti\n",
      "Computer capability: 8.6\n",
      "VRAM: 12GB\n",
      "------------------------------------------------------------\n",
      "GPU number: 1\n",
      "Name: NVIDIA GeForce GTX 750\n",
      "Computer capability: 5.0\n",
      "VRAM: 1GB\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# gpu 상태 확인\n",
    "GET_DEVICE = GetDevice()\n",
    "GET_DEVICE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device 설정\n",
    "GPU = 0\n",
    "DEVICE = GET_DEVICE(GPU)\n",
    "torch.cuda.set_device(DEVICE)\n",
    "\n",
    "# data loader 관련 설정\n",
    "DATASET_CLASS = ImgDataset          # dataset의 class\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 224                      # 고정된 image의 크기\n",
    "RESIZE_HOW = 2                      # resize 방법\n",
    "RESIZE_HOW_LIST = [2, 3, 4]         # 무작위 resize 시, 방법의 list\n",
    "RESIZE_PADDING_COLOR = \"random\"     # resize padding 시, pixel의 색\n",
    "WORKER = 0                          # DataLoader의 num_worker\n",
    "\n",
    "# early stopping 시 경로\n",
    "ESTOP_PATH = f\"{SOURCE}/{ESPOINT_DIR}/process_{PROCESS_ID}\"\n",
    "\n",
    "# process 진행 중 생성되는 파일들이 저장되는 초기 디렉터리 초기화 여부\n",
    "MAKE_NEW_DEFAULT_DIR = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3. Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_DICT = {\n",
    "    'lr':0.0001,\n",
    "    'betas':(0.9, 0.999),\n",
    "    'eps':1e-08,\n",
    "    'clipping_max_norm':5\n",
    "}\n",
    "OPTIM_INS = Optim(name='Adam', hp_dict=HP_DICT)\n",
    "\n",
    "\n",
    "LOSS_FN = nn.BCEWithLogitsLoss()\n",
    "LABEL_TYPE_INS = LabelDtype(loss_fn=LOSS_FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "### Process 1. make key_df\n",
    "* key_df는 img의 절대 경로(\"path\")와 label(\"label\") 두 개의 컬럼으로 구성된 DataFrame 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 정보\n",
    "TRAIN_SET = \"/mnt/d/rawdata/dogs-vs-cats/train/\"        # train set의 경로\n",
    "TEST_SET = \"/mnt/d/rawdata/dogs-vs-cats/test1/\"         # test set의 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/cat.0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/cat.1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/cat.10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/cat.100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/cat.1000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/dog.9995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/dog.9996.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/dog.9997.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/dog.9998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>/mnt/d/rawdata/dogs-vs-cats/train/dog.9999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path  label\n",
       "0         /mnt/d/rawdata/dogs-vs-cats/train/cat.0.jpg      0\n",
       "1         /mnt/d/rawdata/dogs-vs-cats/train/cat.1.jpg      0\n",
       "2        /mnt/d/rawdata/dogs-vs-cats/train/cat.10.jpg      0\n",
       "3       /mnt/d/rawdata/dogs-vs-cats/train/cat.100.jpg      0\n",
       "4      /mnt/d/rawdata/dogs-vs-cats/train/cat.1000.jpg      0\n",
       "...                                               ...    ...\n",
       "24995  /mnt/d/rawdata/dogs-vs-cats/train/dog.9995.jpg      1\n",
       "24996  /mnt/d/rawdata/dogs-vs-cats/train/dog.9996.jpg      1\n",
       "24997  /mnt/d/rawdata/dogs-vs-cats/train/dog.9997.jpg      1\n",
       "24998  /mnt/d/rawdata/dogs-vs-cats/train/dog.9998.jpg      1\n",
       "24999  /mnt/d/rawdata/dogs-vs-cats/train/dog.9999.jpg      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key_df 생성\n",
    "path_list = GetAbsolutePath(None).get_all_path(parents_path=TRAIN_SET)\n",
    "key_df = make_basic_key_df(\n",
    "    paths=path_list,\n",
    "    labels=[re.split(r\".+/\", i, maxsplit=1)[1].split('.')[0] for i in path_list]\n",
    ")\n",
    "# label을 이진 분류로 변환\n",
    "key_df['label'] = binary_label_convertor(array=key_df['label'], positive_class='dog')\n",
    "\n",
    "# 이해를 돕기 위한 key_df 출력\n",
    "key_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process 2. make idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKE_NEW_IDX_DICT = True                            # idx_dict을 새로 생성할지 여부\n",
    "IDX_DICT_PATH = f\"{SOURCE}/idx_dict.pickle\"         # idx_dict이 저장될 경로\n",
    "\n",
    "# idx_dict 생성 방식\n",
    "K_SIZE = 5                  # k-fold의 크기 (Stratified sampling)\n",
    "TEST_RATIO = 0.2            # test dataset ratio\n",
    "VALID_RATIO = 0.1           # validation dataset ratio, None인 경우 생성하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기초 디렉터리 생성\n",
    "make_basic_directory(source=SOURCE, estop_dir=ESPOINT_DIR, log=LOG, result=RESULT, make_new=MAKE_NEW_DEFAULT_DIR)\n",
    "\n",
    "# idx_dict 생성\n",
    "IDX_DICT = do_or_load(\n",
    "    savepath=IDX_DICT_PATH, makes_new=MAKE_NEW_IDX_DICT, \n",
    "    fn=make_stratified_idx_dict,\n",
    "    key_df=key_df, stratified_columns=['label'], is_binary=True,\n",
    "    path_col='path', label_col='label', \n",
    "    k_size=K_SIZE, test_ratio=TEST_RATIO, valid_ratio=VALID_RATIO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process 3. make option instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = Option(\n",
    "    process_id=PROCESS_ID,\n",
    "    model_name=MODEL_NAME, pretrained=PRETRAINED, device=DEVICE, idx_dict=IDX_DICT,\n",
    "    optimizer=OPTIM_INS, loss_fn=LOSS_FN, label_type_fn=LABEL_TYPE_INS, use_amp=USE_AMP, use_clipping=USE_CLIPPING,\n",
    "    img_size=IMG_SIZE, resize_how=RESIZE_HOW, resize_how_list=RESIZE_HOW_LIST, resize_padding_color=RESIZE_PADDING_COLOR,\n",
    "    dataset_class=DATASET_CLASS, augments=sample_augment, batch_size=BATCH_SIZE, worker=WORKER,\n",
    "    img_channel=IMG_CHANNEL, class_size=CLASS_SIZE, custom_header=CUSTOM_HEAD_FN,\n",
    "    tuner_how=2, hp_dict=HP_DICT, verbose=VERBOSE,\n",
    "    log_parents=f\"{LOG}\", results_parents=f\"{RESULT}\", espoint_parents=f\"{SOURCE}/{ESPOINT_DIR}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process 4. model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GGUtils.utils.path import new_dir_maker, make_null_list_pickle, load_pickle, save_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log:\n",
    "    def __init__(self, log_dir, process_id):\n",
    "\n",
    "        self.parents_path = f\"{log_dir}/{process_id}\"\n",
    "        self.iterator_py = f\"{self.parents_path}/iterator.py\"\n",
    "        self.epoch_py = f\"{self.parents_path}/epoch.py\"\n",
    "        self.k = None\n",
    "\n",
    "\n",
    "    def make(self):\n",
    "        new_dir_maker(self.parents_path)\n",
    "        make_null_list_pickle(self.iterator_py)\n",
    "        make_null_list_pickle(self.epoch_py)\n",
    "\n",
    "\n",
    "    def read(self, open_epoch_py:bool=False)->List[Any]:\n",
    "        pickle_path = self.epoch_py if open_epoch_py else self.iterator_py\n",
    "        return load_pickle(pickle_path)\n",
    "    \n",
    "\n",
    "    def write(self, data:List[Any], open_epoch_py:bool=False):\n",
    "        pickle_path = self.epoch_py if open_epoch_py else self.iterator_py\n",
    "        save_pickle(data, pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 전 모든 seed 고정\n",
    "set_seed_everything(seed=SEED)\n",
    "\n",
    "log_ins = Log(log_dir=option.log_parents, process_id=option.process_id)\n",
    "log_ins.make()\n",
    "\n",
    "for k in option.idx_dict.keys():\n",
    "    \n",
    "    k_idx_dict = option.idx_dict[k]     # k-fold에 대한 idx_dict\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log 설정\n",
    "log_ins.k = k\n",
    "\n",
    "# Data Loader 정의\n",
    "loader = GetLoader(\n",
    "    dataset_class=option.dataset_class, idx_dict=k_idx_dict,\n",
    "    augments=option.augments, batch_size=option.batch_size, workers=option.worker, \n",
    "    resize=option.img_size, resize_how=option.resize_how, resize_how_list=option.resize_how_list,\n",
    "    resize_padding_color = option.resize_padding_color\n",
    ")\n",
    "\n",
    "# model 정의\n",
    "model = Classification(\n",
    "    model_name=option.model_name, pretrained=option.pretrained, \n",
    "    channel=option.img_channel, class_size=option.class_size,\n",
    "    custom_head_fn=option.custom_header\n",
    ").to(option.device)\n",
    "\n",
    "# Optimizer 설정\n",
    "optimizer = option.optimizer(param=model.parameters())\n",
    "grad_scaler = torch.GradScaler(device=option.device) if option.use_amp else None\n",
    "back_propagation = BackPropagation(\n",
    "    optimizer=optimizer, use_amp=option.use_amp, grad_scaler=grad_scaler,\n",
    "    use_clipping=option.use_clipping, \n",
    "    max_norm=option.hp_dict['clipping_max_norm'] if 'clipping_max_norm' in option.hp_dict else None\n",
    ")\n",
    "\n",
    "# Fine tuning 방법 정의\n",
    "tuner = Tuner(model, how=2, freezing_ratio=0.9)\n",
    "tuner(epoch=0)      # model parameter 초기 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification:\n",
    "    def __init__(self, model, loader, optimizer, back_propagation, log_ins, option):\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "        self.optimizer = optimizer\n",
    "        self.back_propagation = back_propagation\n",
    "        self.log_ins = log_ins\n",
    "        self.option = option\n",
    "\n",
    "\n",
    "    def _fit_epoch(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def _fit_iterator(self)->Tuple[float, str]:\n",
    "        start = time.time()\n",
    "        loss_list = []\n",
    "        for imgs, labels in loader.train:\n",
    "\n",
    "            # load to device\n",
    "            imgs = imgs.to(self.option.device)\n",
    "            # label dtype을 loss_fn에 맞게 수정 및 shape 등 변형\n",
    "            labels = option.label_type_fn(labels).reshape(-1, 1).to(self.option.device)\n",
    "\n",
    "            # AMP\n",
    "            with torch.autocast(device_type=option.device, enabled=self.option.use_amp):\n",
    "                output = model(imgs)\n",
    "                loss = option.loss_fn(output, labels)\n",
    "                \n",
    "            # back propagation\n",
    "            back_propagation(loss)\n",
    "\n",
    "            # loss log\n",
    "            loss_list.append(loss.item())\n",
    "        \n",
    "        # iterator의 loss 평균, 종료 시간 출력\n",
    "        return np.mean(loss_list), time_checker(start)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INS = Classification(\n",
    "    model=model, loader=loader.train, optimizer=optimizer, \n",
    "    back_propagation=back_propagation, log_ins=log_ins, option=option\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "loss_list = []\n",
    "for imgs, labels in loader.train:\n",
    "\n",
    "    # load to device\n",
    "    imgs = imgs.to(TEST_INS.option.device)\n",
    "    # label dtype을 loss_fn에 맞게 수정 및 shape 등 변형\n",
    "    labels = option.label_type_fn(labels).reshape(-1, 1).to(TEST_INS.option.device)\n",
    "\n",
    "    # AMP\n",
    "    with torch.autocast(device_type=option.device, enabled=TEST_INS.option.use_amp):\n",
    "        output = model(imgs)\n",
    "        loss = option.loss_fn(output, labels)\n",
    "        \n",
    "    # back propagation\n",
    "    back_propagation(loss)\n",
    "\n",
    "    # loss log\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "# class Scheduler:\n",
    "#     def __init__(self, name:str, hp_dict:Dict[str, Any]):\n",
    "#         self.methods = {\n",
    "#             'LambdaLR': lr_scheduler.LambdaLR,\n",
    "#             'MultiplicativeLR': lr_scheduler.MultiplicativeLR,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             'StepLR': lr_scheduler.StepLR,\n",
    "#             'MultiStepLR': lr_scheduler.MultiStepLR,\n",
    "#             'ExponentialLR': lr_scheduler.ExponentialLR,\n",
    "#             'CosineAnnealingLR': lr_scheduler.CosineAnnealingLR,\n",
    "#             'CyclicLR': lr_scheduler.CyclicLR,\n",
    "#             'CosineAnnealingWarmRestarts': lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "#             'ReduceLROnPlateau': lr_scheduler.ReduceLROnPlateau,\n",
    "#             'OneCycleLR': lr_scheduler.OneCycleLR,\n",
    "#             'PolynomialLR': lr_scheduler.PolynomialLR,\n",
    "#             'LinearLR': lr_scheduler.LinearLR,\n",
    "#             'ConstantLR': lr_scheduler.ConstantLR,\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             'ChainedScheduler': lr_scheduler.ChainedScheduler,\n",
    "#             'SequentialLR': lr_scheduler.SequentialLR,\n",
    "            \n",
    "#         }\n",
    "\n",
    "\n",
    "#     def lambdalr(self):\n",
    "#         pass\n",
    "\n",
    "\n",
    "# class Schedulers:\n",
    "#     def __init__(self):\n",
    "#         pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_e4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
